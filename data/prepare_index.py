import os
import time
import argparse
import pandas as pd
import numpy as np
from tqdm import tqdm
import torch
from sentence_transformers import SentenceTransformer
import faiss
import re
import psutil
import shutil

def clean_text(text: str) -> str:
    text = re.sub(r"[ã€ã€‘\[\]ï¼ˆï¼‰()ã€Šã€‹<>]", "", str(text))
    text = re.sub(r"[Â§#ï¿¥@&*~^]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def convert_stars(row) -> int:
    """ç»Ÿè®¡äº®èµ·çš„æ˜Ÿæ˜Ÿæ•°ï¼Œæ¯åˆ—éç©ºå³è®¡1"""
    return sum([str(row.get(f"stars{i}", "")).strip() != "" for i in range(1, 6)])

def prepare_dataframe(raw_path: str) -> pd.DataFrame:
    df = pd.read_csv(raw_path)

    df["comment"] = df["comment"].astype(str).fillna("").str.strip()
    df = df[df["comment"].str.len() >= 5].copy()
    df["clean_text"] = df["comment"].apply(clean_text)

    # ç¡®ä¿starså­—æ®µå­˜åœ¨
    for i in range(1, 6):
        if f"stars{i}" not in df.columns:
            df[f"stars{i}"] = ""

    df["star_rating"] = df.apply(convert_stars, axis=1)

    return df[["id", "author", "comment", "clean_text", "star_rating"]]

def build_index(input_csv, output_dir, model_name, device):
    start_time = time.time()

    os.makedirs(output_dir, exist_ok=True)

    print("ğŸ”¹ åŠ è½½å¹¶æ¸…æ´—åŸå§‹æ•°æ®...")
    df = prepare_dataframe(input_csv)
    sentences = df["clean_text"].tolist()
    print(f"ğŸ”¹ æ¸…æ´—åè¯„è®ºæ•°: {len(sentences)}")

    print("ğŸ”¹ åŠ è½½å‘é‡æ¨¡å‹:", model_name)
    model = SentenceTransformer(model_name, device=device)

    batch_size = 64
    embeddings = []

    print("ğŸ”¹ å¼€å§‹å‘é‡åŒ–ï¼ˆBatch Size = %dï¼‰..." % batch_size)
    with torch.no_grad():
        for i in tqdm(range(0, len(sentences), batch_size)):
            batch = sentences[i:i + batch_size]
            vecs = model.encode(batch, convert_to_numpy=True)
            embeddings.append(vecs)

    embeddings = np.vstack(embeddings)
    print(f"âœ… å‘é‡åŒ–å®Œæˆï¼šå…± {embeddings.shape[0]} æ¡ï¼Œç»´åº¦ {embeddings.shape[1]}")

    # æ„å»ºç´¢å¼•
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)

    # ä¿å­˜ç´¢å¼•
    faiss.write_index(index, os.path.join(output_dir, "faiss_index.index"))
    df.to_csv(os.path.join(output_dir, "faiss_docs.csv"), index=False)

    # ä¸è¦†ç›–åŸæ–‡ä»¶
    original_name = os.path.basename(input_csv)
    if not input_csv.startswith(output_dir):
        shutil.copy(input_csv, os.path.join(output_dir, original_name))

    # èµ„æºç»Ÿè®¡
    ram = psutil.virtual_memory().used / 1024 / 1024
    cpu = time.time() - start_time
    print(f"ğŸ§  å†…å­˜ä½¿ç”¨ï¼š{ram:.2f} MB")
    print(f"â±ï¸ æ€»è€—æ—¶ï¼š{cpu:.2f} ç§’")

    with open(os.path.join(output_dir, "resource_log.txt"), "w", encoding="utf-8") as f:
        f.write(f"å†…å­˜ä½¿ç”¨: {ram:.2f} MB\n")
        f.write(f"è€—æ—¶: {cpu:.2f} ç§’\n")
        f.write(f"æ•°æ®æ¡æ•°: {len(sentences)}\n")
        f.write(f"å‘é‡ç»´åº¦: {embeddings.shape[1]}\n")

if __name__ == "__main__":
    # è‡ªåŠ¨è·å–å½“å‰è„šæœ¬ç›®å½•
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    default_csv_path = os.path.join(BASE_DIR, "bilibili_gzxb.csv")
    default_output_dir = os.path.join(BASE_DIR, "..", "vector_index")

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--input_csv",
        default=default_csv_path,
        help="åŸå§‹æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤è„šæœ¬åŒç›®å½•ä¸‹çš„bilibili_gzxb.csv"
    )
    parser.add_argument(
        "--output_dir",
        default=default_output_dir,
        help="å‘é‡ç´¢å¼•å’Œæ¸…æ´—æ•°æ®ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤é¡¹ç›®æ ¹ç›®å½•vector_indexæ–‡ä»¶å¤¹"
    )
    parser.add_argument(
        "--model_name",
        default="BAAI/bge-large-zh-v1.5",
        help="SentenceTransformeræ¨¡å‹å"
    )
    parser.add_argument(
        "--device",
        default=None,
        help="è¿è¡Œè®¾å¤‡ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹"
    )
    args = parser.parse_args()

    # è‡ªåŠ¨è®¾å¤‡é€‰æ‹©ï¼šä¼˜å…ˆcudaï¼Œå¦åˆ™cpu
    if args.device is None:
        args.device = "cuda" if torch.cuda.is_available() else "cpu"
        if args.device == "cuda":
            print("æ£€æµ‹åˆ°å¯ç”¨CUDAï¼Œä½¿ç”¨GPUåŠ é€Ÿã€‚")
        else:
            print("æœªæ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨CPUè¿è¡Œã€‚")

    build_index(args.input_csv, args.output_dir, args.model_name, args.device)
