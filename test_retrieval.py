from models.embedder import load_embedder
from models.retriever import load_retriever
import torch
def main():
    query = "è¿™éƒ¨åŠ¨ç”»é€‚åˆå°å­¦ç”Ÿçœ‹å—ï¼Ÿ"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ”§ æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹ï¼Œä½¿ç”¨è®¾å¤‡: {device}")

    print("ğŸ”§ æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹...")
    embedder = load_embedder(device=device)
    print("ğŸ“¦ æ­£åœ¨åŠ è½½å‘é‡ç´¢å¼•...")
    retriever = load_retriever()

    print("ğŸ” æ­£åœ¨å‘é‡åŒ–æŸ¥è¯¢å¹¶æ£€ç´¢...")
    query_vec = embedder.encode([query])
    docs = retriever.search(query_vec, top_k=3)

    print(f"\nğŸ“„ æ£€ç´¢ç»“æœï¼š")
    for i, doc in enumerate(docs, 1):
        print(f"\n== ç¬¬ {i} æ¡ ==")
        print(doc)

if __name__ == "__main__":
    main()
